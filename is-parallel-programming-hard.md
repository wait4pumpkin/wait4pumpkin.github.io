# 简介

## 并行编程的目标

+ 性能：并不是狭隘地指单核性能，而是要考虑可扩展性（多核运行）
+ 生产率
+ 通用性

越往上层（应用层），生产率越重要，而越底层，性能和通用性越重要

## 并行编程的任务

+ 分割任务

（正确的）任务分割可以极大提升性能和扩展性，但也增大复杂度。处理流程会变复杂，可能需要额外的同步操作

并发的线程数也是有效，每个线程会占用一部分资源，例如CPU Cache、I/O等，并发过多可能导致Cache miss增多，I/O不够高效

生产率会降低，更难调试和理解

+ 并行访问控制

可能需要远程访问，同时要协调多线程对共享资源的访问

+ 资源分割和复制

对资源的分割是自然的并行方式，例如按规则分割用户数据、矩阵分行列处理

+ 与硬件的交互

根据硬件做定制优化


# 硬件和它的习惯

## 概述

阻碍CPU全速运行的因素

+ 流水线：长流水线的CPU要达到最佳性能，需要程序给出高度可预测的控制流。像很短的循环、或者大量的虚函数，难以预测代码的分支走向，会导致CPU的流水线被刷新
+ 内存引用：就是指针，无法有效预测数据位置，导致Cache miss
+ 原子操作：古董CPU是通过锁总线实现的，性能影响很大。现在主流的是锁Cache line，但是当数据跨越Cache line时，依然有可能锁总线
+ 内存屏障：确保CPU不会乱序执行，因此也必定降低性能
+ Cache miss：其他核心修改了变量值，导致当前核心的访问未命中
+ I/O操作

## 开销

最好情况的CAS（修改的变量就在当前核心独占）是数十个时钟周期，最好情况的加锁是两倍的CAS（两个原子量）

数个核心之间可能会有独立的互联模块，搜索Cache时先检查本地缓存，再通过互联模块搜索附近的核心，若没有再通过全局的系统互联查找其他核心的缓存

## 硬件的免费午餐

最严重的限制在于有限的光速。5GHz的时钟周期内，光传播的距离大约为3cm。而电子在硅中的移动速度是光速的1/30到1/3

+ 3D集成：纵向叠加硅制芯片，缩短路径
+ 新材料和新工艺
+ 提升电子速度
+ 专用加速器：GPU、MMX、SSE、VMX，加密


# 办事的家伙




# 数据所有权

避免锁的同步开销的最简单方法是，把数据进行包装，并且保证只有一个线程访问和修改。

## 多进程

进程间不共享内存，没有同步开销

## 部分数据所有权和pthread线程库

例如每个线程只修改更新对应线程的数据（tls），跨线程的只读不修改

## 函数输送

XXX
