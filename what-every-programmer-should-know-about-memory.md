## CPU caches

如果采用SRAM和DRAM混合，把SRAM映射到虚拟内存地址上，管理成本会太高，不同处理器的SRAM大小不同，各个程序也会申请私有的SRAM，造成额外的同步消耗（SRAM太小，进程切换的时候基本上都要刷新）

因此系统或者用户无法控制SRAM，而是由CPU自动管理的资源。SRAM用于保存主存有可能被使用的数据，前提就是程序代码和数据的时空局部性，即使访问的物理地址不是连续的

指令和数据的Cache是独立的,因为代码区和数据区是分离的,同时指令解码比较耗时，一般也只有L1 Cache才区分（L1i和L1d），L2是可能是一个或多个核心共享，L3一般是所有核心共享，下一级Cache的数据流事实上不需要经过上级Cache

最简单的缓存配置，是CPU和Cache之间有特殊的高速通道，主存和Cache都挂在FSB上，CPU不再直连主存，数据的读写都经过Cache。

默认情况下，CPU读写的数据都是在Cache内。缓存条目需要额外的标记信息（可以根据虚拟地址查，也可以根据物理地址，取决于缓存的实现），一个字一个标记成本不划算，因此缓存是以Cache line为单位（现在一般为64字节）

