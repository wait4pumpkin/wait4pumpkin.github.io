# 可靠、可扩展与可维护的应用系统

核心设计目标
+ 可靠
+ 可扩展
+ 可维护


# 数据模型与查询语言

+ 文档模型
+ 关系模型
+ 图模型

SQL数据模型和面向对象的编程模型不匹配，必须要加一个转换层，如ActiveRecord、Hibernate等ORM（Object Relational Mapping）框架

文档数据库事实上并不是无模式，应该理解为读时模式，数据结构是隐式的，在读时才解释，类似动态类型检查
关系数据库是写时模式，模式是显式的，类似静态编译检查

如果需要频繁访问整个文档，则存储局部性会发挥优势。
若每次只访问小部分，但通常会加载整个文档造成浪费。
修改时一般需要重写整个文档，当文档增大时可能无法原地覆盖。

文档数据库和关系数据库的融合，关系型支持XML、JSON等，文档型支持联结（可能是在驱动层完成）

声明式比命令式更适合并行，因为没有执行执行顺序，仅指定结果的模式，数据库可在限定内优化
MapReduce介于两者之间，map和reduce内的操作必须是无副作用的，只能以传递的数据作为输入，因为可以以任何输入运行，也可以失败重试

Cypher是用于属性图的声明式查询语言
SQL也可以用于图查询（顶点和边两个关系表），问题在于Join的操作数不固定，需要递归（with recursive）

三元存储
所有信息以三部分存储，主体，谓语，客体
主体相当于图的顶点，客体可以是数值，谓语和客体就分别相当于主体属性的键和值；客体是另一个顶点，谓语就是连接两个顶点之间的边的标签

语义网
以三元组的方式存储网站信息，则不同网站的数据可以合并为一个数据网络
RDF（Resource Description Framework）就是这样的机制

SPARQL是采用RDF数据模型的三元存储查询语言
Cypher的模式匹配借用SPARQL

Datalog数据模型类似于三元存储，是谓语（主体，客体）
可以定义新的谓语规则，并引用其他规则，以及递归


# 数据存储与检索

索引是一个权衡，读取加锁，但写速度减慢

P74



# 数据复制

数据复制目的
+ 在地理位置上更接近用户，降低访问延时
+ 部分组件出现故障时，系统仍可继续工作，提高可用性
+ 扩展到多台机器同时提供服务，提高读吞吐量

复制方式
+ 主从复制
+ 多主节点复制
+ 无主节点复制

主从复制
对客户端来说，主副本可写，从副本只读

同步复制
向用户确认时已保证复制完成，主节点故障时，数据不丢失

异步复制
主节点故障时，尚未复制的请求会丢失。已确认的操作无法保证数据的持久化

一般数据库开启了同步复制，也只是把一个从节点配置为同步，其他为异步模式。当主节点故障时，能保证一个从节点有完整数据，再选取另一个从节点修改为同步模式
与此对应的是全异步模式，虽然看起来不安全但被广泛使用，特别是节点数量巨大或者分布地域广阔

链式复制
为了保证在数据不丢失的前提，提高复制的性能和可用性
多个节点串联，head负责接收写请求，tail负责接收读请求
写请求从head开始逐个节点向后传递，到了tail才回复客户端完成
manager通过Paxos选举，负责节点加减
头节点出现故障时，由于还没回复客户端成功，因而没问题
尾节点出现故障时，更前的节点信息会更多，不会出现一致性问题
原始实现的问题在于读的性能太低，受限于单个节点
High throughput chain replication for read-mostly workloads
扩展到可以从所有节点读，为保证一致性，每个数据都包含版本号，标记clean或dirty
写入新数据的时候置为dirty，当尾节点写入完成时会广播所有节点最新版本，符合条件的dirty数据变为clean
clean的数据可以直接返回，dirty的数据会转而查询尾节点
同时为提供写速度，头节点写入时会广播到所有节点相关数据，其他节点可以提前生成暂未生效的新版本，然后等待逐级传递生效

配置新的从节点
取主节点的某个时间的快照，用于初始化从节点
从节点连接主节点后，请求快照之后的更改日志，不断追赶主节点的数据变化，这和从节点失效重启是同样的原理

主节点失效重选可能出现的问题（这些问题的权衡就是分布式系统的核心基础问题）
+ 如果使用了异步复制，新的主节点没有收到原节点的所有数据，原节点可能在短时间内又重现加入集群，新的主节点会收到冲突的写请求，因为原节点还没发生角色变化继续在同步。如果丢弃原主节点未完成的请求就违背了持久化的原则
+ 如果有其他系统依赖于数据库内容协作的话，可能造成严重的问题。例如非同步的节点被提升为主节点，部分数据被rollback（如作为索引的自增计数器），其他系统的数据会发生冲突或者逻辑异常
+ 脑裂，两个节点均自认为是主节点，并同时接收写请求，最后数据可能被丢失或者破坏
+ 设置合理的超时检测主节点是否失效，超时短出现不必要的切换，超时长恢复时间太长

P152


# 分布式系统的挑战

基本原则：所有可能出错的事情一定会出错

对于单机程序，总倾向于确定性的结果，要么是功能完全正常，要么是完全失效，不会介于两者之间
而分布式系统的复杂性体现在存在大量的部分失效问题，同时部分失效也是不确定的（有时正常，有时失败，甚至无法确定是否成功）

构建大规模计算系统的几个思路
一个极端是HPC（High-Performance Computing）
另一个极端是云计算
传统企业数据中心谓语两个极端之间

HPC对任务进行定时快照并持久存储，当出现单点故障时停止整个集群任务，把局部失效提升为整体失效，更像是单节点系统而不是分布式系统
同时采用专用硬件，通过共享内存方式通信，通常有特定的网络拓扑结构
节点位置靠近

基于互联网的服务系统（在不可靠的组件上构建可靠的系统）
大部分要求24小时在线，不允许停止集群修复故障，能容忍部分失败节点
采用成本低廉且故障率高的通用机器
基于IP和以太网通信
分布全球的数据中心，延时更高更不可靠

系统的可靠性并不是简单取决于最不可靠的组件
系统可以比底层组件更可靠，但可靠性有上限
如纠错码、TCP重传等

异步网络中发送者甚至不知道是否完成发送，只能等待回复。没有收到回复，可能有多种原因。
通常使用超时判定请求是否到达，即使是超时了，也无法确定远端是否接收到
一个请求是否执行成功，需要依赖应用层的回复（TCP发送成功并不代表应用层处理了）

P271


MTTF(Mean Time to Failure)
对于不可修复系统，系统的平均寿命指系统发生失效前的平均工作时间或工作次数

MTBF(Mean Time between Failure)
对于可修复系统，系统的寿命是指两次相邻失效之间的工作时间。

MTTR(Mean Time to Repair)
可修复产品的平均修复时间

可用度A = MTBF / (MTBF + MTTR)

数据规范化

ATM(Asynchronous Transfer Mode)
曾是以太网的竞争对手，最终除电话网核心交换机外无大规模部署


